'''
Now that you've seen the effect that tuning has on the overall performance of your XGBoost model, let's turn the question on its head and see if you can figure out when tuning your model might not be the best idea. 
Given that model tuning can be time-intensive and complicated, which of the following scenarios would NOT call for careful tuning of your model?
'''

Possible Answers = 2

1. You have lots of examples from some dataset and very many features at your disposal.

2. You are very short on time before you must push an initial model to production and have little data to train your model on.

3. You have access to a multi-core (64 cores) server with lots of memory (200GB RAM) and no time constraints.

4. You must squeeze out every last bit of performance out of your xgboost model.
